{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "unnecessary-river",
   "metadata": {
    "papermill": {
     "duration": 0.022726,
     "end_time": "2021-04-18T20:00:45.561391",
     "exception": false,
     "start_time": "2021-04-18T20:00:45.538665",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "For this project an ANN will be implemented in a way that will allow the modification of hyper parameters to enhance the accuracy of the predictions.\n",
    "This will be done with the use of many helper fuction and a main fuction that will load the data and call the helper functions to train the model.\n",
    "\n",
    "In **version 0.1**** we will be using a 3 layers deep learning model where the activations for the  layers 1 through L-1 is a relu fuction with a sigmoid function for the last layer L and where we are using he initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "sound-logging",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-04-18T20:00:45.614896Z",
     "iopub.status.busy": "2021-04-18T20:00:45.614204Z",
     "iopub.status.idle": "2021-04-18T20:00:45.822021Z",
     "shell.execute_reply": "2021-04-18T20:00:45.821018Z"
    },
    "papermill": {
     "duration": 0.239369,
     "end_time": "2021-04-18T20:00:45.822299",
     "exception": false,
     "start_time": "2021-04-18T20:00:45.582930",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/titanic/train.csv\n",
      "/kaggle/input/titanic/test.csv\n",
      "/kaggle/input/titanic/gender_submission.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt #For plotting\n",
    "from statistics import mean\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "get_ipython().magic('matplotlib inline')\n",
    "plt.rcParams['figure.figsize'] = (5.0, 4.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "get_ipython().magic('load_ext autoreload')\n",
    "get_ipython().magic('autoreload 2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liquid-large",
   "metadata": {
    "papermill": {
     "duration": 0.021846,
     "end_time": "2021-04-18T20:00:45.867279",
     "exception": false,
     "start_time": "2021-04-18T20:00:45.845433",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **======================= HERE STARTS HELPER METHODS ==========================**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "distributed-publisher",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-18T20:00:45.917899Z",
     "iopub.status.busy": "2021-04-18T20:00:45.916829Z",
     "iopub.status.idle": "2021-04-18T20:00:45.945714Z",
     "shell.execute_reply": "2021-04-18T20:00:45.945163Z"
    },
    "papermill": {
     "duration": 0.05664,
     "end_time": "2021-04-18T20:00:45.945871",
     "exception": false,
     "start_time": "2021-04-18T20:00:45.889231",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sigmoid(Z):\n",
    "    \"\"\"\n",
    "    Implements the sigmoid activation in numpy\n",
    "    \n",
    "    Arguments:\n",
    "    Z -- numpy array of any shape\n",
    "    \n",
    "    Returns:\n",
    "    A -- output of sigmoid(z), same shape as Z\n",
    "    cache -- returns Z as well, useful during backpropagation\n",
    "    \"\"\"\n",
    "    \n",
    "    A = 1/(1+np.exp(-Z))\n",
    "    cache = Z\n",
    "    \n",
    "    return A, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "biblical-aberdeen",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-18T20:00:46.000889Z",
     "iopub.status.busy": "2021-04-18T20:00:45.999743Z",
     "iopub.status.idle": "2021-04-18T20:00:46.027004Z",
     "shell.execute_reply": "2021-04-18T20:00:46.027677Z"
    },
    "papermill": {
     "duration": 0.057532,
     "end_time": "2021-04-18T20:00:46.027875",
     "exception": false,
     "start_time": "2021-04-18T20:00:45.970343",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sigmoid_backward(dA, cache):\n",
    "    \"\"\"\n",
    "    Implement the backward propagation for a single SIGMOID unit.\n",
    "    Arguments:\n",
    "    dA -- post-activation gradient, of any shape\n",
    "    cache -- 'Z' where we store for computing backward propagation efficiently\n",
    "    Returns:\n",
    "    dZ -- Gradient of the cost with respect to Z\n",
    "    \"\"\"\n",
    "    \n",
    "    Z = cache\n",
    "    \n",
    "    s = 1/(1+np.exp(-Z))\n",
    "    dZ = dA * s * (1-s)\n",
    "    \n",
    "    assert (dZ.shape == Z.shape)\n",
    "    \n",
    "    return dZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "confidential-bracelet",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-18T20:00:46.076299Z",
     "iopub.status.busy": "2021-04-18T20:00:46.075577Z",
     "iopub.status.idle": "2021-04-18T20:00:46.103633Z",
     "shell.execute_reply": "2021-04-18T20:00:46.104160Z"
    },
    "papermill": {
     "duration": 0.053945,
     "end_time": "2021-04-18T20:00:46.104355",
     "exception": false,
     "start_time": "2021-04-18T20:00:46.050410",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def relu(Z):\n",
    "    \"\"\"\n",
    "    Implement the RELU function.\n",
    "    Arguments:\n",
    "    Z -- Output of the linear layer, of any shape\n",
    "    Returns:\n",
    "    A -- Post-activation parameter, of the same shape as Z\n",
    "    cache -- a python dictionary containing \"A\" ; stored for computing the backward pass efficiently\n",
    "    \"\"\"\n",
    "    \n",
    "    A = np.maximum(0,Z)\n",
    "    \n",
    "    assert(A.shape == Z.shape)\n",
    "    \n",
    "    cache = Z \n",
    "    return A, cache\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "characteristic-location",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-18T20:00:46.153408Z",
     "iopub.status.busy": "2021-04-18T20:00:46.152652Z",
     "iopub.status.idle": "2021-04-18T20:00:46.181716Z",
     "shell.execute_reply": "2021-04-18T20:00:46.182237Z"
    },
    "papermill": {
     "duration": 0.055636,
     "end_time": "2021-04-18T20:00:46.182445",
     "exception": false,
     "start_time": "2021-04-18T20:00:46.126809",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def relu_backward(dA, cache):\n",
    "    \"\"\"\n",
    "    Implement the backward propagation for a single RELU unit.\n",
    "    Arguments:\n",
    "    dA -- post-activation gradient, of any shape\n",
    "    cache -- 'Z' where we store for computing backward propagation efficiently\n",
    "    Returns:\n",
    "    dZ -- Gradient of the cost with respect to Z\n",
    "    \"\"\"\n",
    "    \n",
    "    Z = cache\n",
    "    dZ = np.array(dA, copy=True) # just converting dz to a correct object.\n",
    "    \n",
    "    # When z <= 0, you should set dz to 0 as well. \n",
    "    dZ[Z <= 0] = 0\n",
    "    \n",
    "    assert (dZ.shape == Z.shape)\n",
    "    \n",
    "    return dZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "demonstrated-daily",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-18T20:00:46.238597Z",
     "iopub.status.busy": "2021-04-18T20:00:46.234360Z",
     "iopub.status.idle": "2021-04-18T20:00:46.266507Z",
     "shell.execute_reply": "2021-04-18T20:00:46.267005Z"
    },
    "papermill": {
     "duration": 0.059192,
     "end_time": "2021-04-18T20:00:46.267217",
     "exception": false,
     "start_time": "2021-04-18T20:00:46.208025",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def initialize_parameters_deep(layer_dims):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    layer_dims -- python array (list) containing the dimensions of each layer in the network\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- python dictionary containing parameters \"W1\", \"b1\", ..., \"WL\", \"bL\":\n",
    "                    Wl -- weight matrix of shape (layer_dims[l], layer_dims[l-1])\n",
    "                    bl -- bias vector of shape (layer_dims[l], 1)\n",
    "    \"\"\"\n",
    "    parameters = {}\n",
    "    L = len(layer_dims)            # number of layers in the network\n",
    "\n",
    "    for l in range(1, L):\n",
    "        parameters['W' + str(l)] = np.random.randn(layer_dims[l], layer_dims[l-1])*np.sqrt(2/layer_dims[l-1])  # Using he initialization\n",
    "        parameters['b' + str(l)] = np.zeros((layer_dims[l], 1))  \n",
    "        \n",
    "        assert(parameters['W' + str(l)].shape == (layer_dims[l], layer_dims[l-1]))\n",
    "        assert(parameters['b' + str(l)].shape == (layer_dims[l], 1))\n",
    "\n",
    "        \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "incorrect-marking",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-18T20:00:46.320017Z",
     "iopub.status.busy": "2021-04-18T20:00:46.319332Z",
     "iopub.status.idle": "2021-04-18T20:00:46.347059Z",
     "shell.execute_reply": "2021-04-18T20:00:46.346469Z"
    },
    "papermill": {
     "duration": 0.057198,
     "end_time": "2021-04-18T20:00:46.347227",
     "exception": false,
     "start_time": "2021-04-18T20:00:46.290029",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def linear_forward(A, W, b):\n",
    "    \"\"\"\n",
    "    Implement the linear part of a layer's forward propagation.\n",
    "\n",
    "    Arguments:\n",
    "    A -- activations from previous layer (or input data): (size of previous layer, number of examples: 891)\n",
    "    W -- weights matrix: numpy array of shape (size of current layer, size of previous layer)\n",
    "    b -- bias vector, numpy array of shape (size of the current layer, 1)\n",
    "\n",
    "    Returns:\n",
    "    Z -- the input of the activation function, also called pre-activation parameter \n",
    "    cache -- a python tuple containing \"A\", \"W\" and \"b\" ; stored for computing the backward pass efficiently\n",
    "    \"\"\"\n",
    "    Z = np.dot(W, A) + b\n",
    "    \n",
    "    assert(Z.shape == (W.shape[0], A.shape[1]))\n",
    "    cache = (A, W, b)\n",
    "    \n",
    "    return Z, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "therapeutic-ghana",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-18T20:00:46.400757Z",
     "iopub.status.busy": "2021-04-18T20:00:46.400046Z",
     "iopub.status.idle": "2021-04-18T20:00:46.427903Z",
     "shell.execute_reply": "2021-04-18T20:00:46.427287Z"
    },
    "papermill": {
     "duration": 0.058241,
     "end_time": "2021-04-18T20:00:46.428054",
     "exception": false,
     "start_time": "2021-04-18T20:00:46.369813",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def linear_activation_forward(A_prev, W, b, activation):\n",
    "    \"\"\"\n",
    "    Implement the forward propagation for the LINEAR->ACTIVATION layer\n",
    "\n",
    "    Arguments:\n",
    "    A_prev -- activations from previous layer (or input data): (size of previous layer, number of examples: 891)\n",
    "    W -- weights matrix: numpy array of shape (size of current layer, size of previous layer)\n",
    "    b -- bias vector, numpy array of shape (size of the current layer, 1)\n",
    "    activation -- the activation to be used in this layer, stored as a text string: \"sigmoid\" or \"relu\"\n",
    "\n",
    "    Returns:\n",
    "    A -- the output of the activation function, also called the post-activation value \n",
    "    cache -- a python tuple containing \"linear_cache\" and \"activation_cache\";\n",
    "             stored for computing the backward pass efficiently\n",
    "    \"\"\"\n",
    "    \n",
    "    if activation == \"sigmoid\":\n",
    "        # Inputs: \"A_prev, W, b\". Outputs: \"A, activation_cache\".\n",
    "        Z, linear_cache = linear_forward(A_prev, W, b)\n",
    "        A, activation_cache = sigmoid(Z)\n",
    "    \n",
    "    elif activation == \"relu\":\n",
    "        # Inputs: \"A_prev, W, b\". Outputs: \"A, activation_cache\".\n",
    "        Z, linear_cache = linear_forward(A_prev, W, b)\n",
    "        A, activation_cache = relu(Z)\n",
    "    \n",
    "    assert (A.shape == (W.shape[0], A_prev.shape[1]))\n",
    "    cache = (linear_cache, activation_cache)\n",
    "\n",
    "    return A, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "brutal-interim",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-18T20:00:46.483722Z",
     "iopub.status.busy": "2021-04-18T20:00:46.482724Z",
     "iopub.status.idle": "2021-04-18T20:00:46.510232Z",
     "shell.execute_reply": "2021-04-18T20:00:46.509556Z"
    },
    "papermill": {
     "duration": 0.058916,
     "end_time": "2021-04-18T20:00:46.510386",
     "exception": false,
     "start_time": "2021-04-18T20:00:46.451470",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def L_model_forward(X, parameters):\n",
    "    \"\"\"\n",
    "    Implement forward propagation for the [LINEAR->RELU]*(L-1) from Layer 1 to Layer L-1 -> LINEAR->SIGMOID computation in Layer L\n",
    "    \n",
    "    Arguments:\n",
    "    X -- data, numpy array of shape (input size, number of examples)\n",
    "    parameters -- output of initialize_parameters_deep()\n",
    "    \n",
    "    Returns:\n",
    "    AL -- last post-activation value\n",
    "    caches -- list of caches containing:\n",
    "                every cache of linear_activation_forward() (there are L-1 of them, indexed from 0 to L-1)\n",
    "    \"\"\"\n",
    "\n",
    "    caches = []\n",
    "    A = X\n",
    "    L = len(parameters) // 2                  # number of layers in the neural network\n",
    "    \n",
    "    # Implement [LINEAR -> RELU]*(L-1) from Layer 1 to Layer L-1. Add \"cache\" to the \"caches\" list.\n",
    "    for l in range(1, L):\n",
    "        A_prev = A \n",
    "        A, cache = linear_activation_forward(A_prev, parameters['W' + str(l)], parameters['b' + str(l)], \"relu\")\n",
    "        caches.append(cache)\n",
    "    \n",
    "    # Implement LINEAR -> SIGMOID in Layer L. Add \"cache\" to the \"caches\" list.\n",
    "    AL, cache = linear_activation_forward(A, parameters['W' + str(L)], parameters['b' + str(L)], \"sigmoid\")\n",
    "    caches.append(cache)\n",
    "    assert(AL.shape == (1,X.shape[1]))\n",
    "            \n",
    "    return AL, caches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "duplicate-delta",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-18T20:00:46.563984Z",
     "iopub.status.busy": "2021-04-18T20:00:46.562935Z",
     "iopub.status.idle": "2021-04-18T20:00:46.591468Z",
     "shell.execute_reply": "2021-04-18T20:00:46.590750Z"
    },
    "papermill": {
     "duration": 0.058063,
     "end_time": "2021-04-18T20:00:46.591630",
     "exception": false,
     "start_time": "2021-04-18T20:00:46.533567",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_cost(AL, Y):\n",
    "    \"\"\"\n",
    "    Implement the cost function\n",
    "\n",
    "    Arguments:\n",
    "    AL -- probability vector corresponding to the label predictions, shape (1, number of examples: 891)\n",
    "    Y -- true \"label\" vector (for example: containing 0 if Did Not survive, 1 if survived), shape (1, number of examples: 891)\n",
    "\n",
    "    Returns:\n",
    "    cost -- cross-entropy cost\n",
    "    \"\"\"\n",
    "\n",
    "    m = Y.shape[1]\n",
    "    \n",
    "    # Compute loss from aL and y.\n",
    "    log_Probs = (np.multiply(np.log(AL),Y)) + (np.multiply(np.log(1-AL),1-Y))\n",
    "    cost = - np.sum(log_Probs)/m\n",
    "    cost = np.squeeze(cost)      # To make sure your cost's shape is what we expect (e.g. this turns [[18]] into 18).\n",
    "    \n",
    "    assert(cost.shape == ())\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "medical-intermediate",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-18T20:00:46.645184Z",
     "iopub.status.busy": "2021-04-18T20:00:46.644506Z",
     "iopub.status.idle": "2021-04-18T20:00:46.672566Z",
     "shell.execute_reply": "2021-04-18T20:00:46.671958Z"
    },
    "papermill": {
     "duration": 0.05776,
     "end_time": "2021-04-18T20:00:46.672711",
     "exception": false,
     "start_time": "2021-04-18T20:00:46.614951",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def linear_backward(dZ, cache):\n",
    "    \"\"\"\n",
    "    Implement the linear portion of backward propagation for a single layer (layer l)\n",
    "\n",
    "    Arguments:\n",
    "    dZ -- Gradient of the cost with respect to the linear output (of current layer l)\n",
    "    cache -- tuple of values (A_prev, W, b) coming from the forward propagation in the current layer\n",
    "\n",
    "    Returns:\n",
    "    dA_prev -- Gradient of the cost with respect to the activation (of the previous layer l-1), same shape as A_prev\n",
    "    dW -- Gradient of the cost with respect to W (current layer l), same shape as W\n",
    "    db -- Gradient of the cost with respect to b (current layer l), same shape as b\n",
    "    \"\"\"\n",
    "    A_prev, W, b = cache\n",
    "    m = A_prev.shape[1]\n",
    "\n",
    "    dW = np.dot(dZ,A_prev.T)/m\n",
    "    db = np.sum(dZ, axis = 1, keepdims = True)/m\n",
    "    dA_prev = np.dot(W.T,dZ)\n",
    "    \n",
    "    assert (dA_prev.shape == A_prev.shape)\n",
    "    assert (dW.shape == W.shape)\n",
    "    assert (db.shape == b.shape)\n",
    "    \n",
    "    return dA_prev, dW, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "incomplete-project",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-18T20:00:46.727227Z",
     "iopub.status.busy": "2021-04-18T20:00:46.726551Z",
     "iopub.status.idle": "2021-04-18T20:00:46.753789Z",
     "shell.execute_reply": "2021-04-18T20:00:46.754313Z"
    },
    "papermill": {
     "duration": 0.05862,
     "end_time": "2021-04-18T20:00:46.754512",
     "exception": false,
     "start_time": "2021-04-18T20:00:46.695892",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def linear_activation_backward(dA, cache, activation):\n",
    "    \"\"\"\n",
    "    Implement the backward propagation for the LINEAR->ACTIVATION layer.\n",
    "    \n",
    "    Arguments:\n",
    "    dA -- post-activation gradient for current layer l \n",
    "    cache -- tuple of values (linear_cache, activation_cache) we store for computing backward propagation efficiently\n",
    "    activation -- the activation to be used in this layer, stored as a text string: \"sigmoid\" or \"relu\"\n",
    "    \n",
    "    Returns:\n",
    "    dA_prev -- Gradient of the cost with respect to the activation (of the previous layer l-1), same shape as A_prev\n",
    "    dW -- Gradient of the cost with respect to W (current layer l), same shape as W\n",
    "    db -- Gradient of the cost with respect to b (current layer l), same shape as b\n",
    "    \"\"\"\n",
    "    linear_cache, activation_cache = cache\n",
    "    \n",
    "    if activation == \"relu\":\n",
    "        dZ = relu_backward(dA, activation_cache)\n",
    "        dA_prev, dW, db = linear_backward(dZ, linear_cache)\n",
    "        \n",
    "    elif activation == \"sigmoid\":\n",
    "        dZ = sigmoid_backward(dA, activation_cache)\n",
    "        dA_prev, dW, db = linear_backward(dZ, linear_cache)\n",
    "    \n",
    "    return dA_prev, dW, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cardiac-defeat",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-18T20:00:46.810932Z",
     "iopub.status.busy": "2021-04-18T20:00:46.810241Z",
     "iopub.status.idle": "2021-04-18T20:00:46.839048Z",
     "shell.execute_reply": "2021-04-18T20:00:46.838496Z"
    },
    "papermill": {
     "duration": 0.061339,
     "end_time": "2021-04-18T20:00:46.839220",
     "exception": false,
     "start_time": "2021-04-18T20:00:46.777881",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def L_model_backward(AL, Y, caches):\n",
    "    \"\"\"\n",
    "    Implement the backward propagation for the [LINEAR->RELU] * (L-1) -> LINEAR -> SIGMOID group\n",
    "    \n",
    "    Arguments:\n",
    "    AL -- probability vector, output of the forward propagation (L_model_forward())\n",
    "    Y -- true \"label\" vector (containing 0 if non-cat, 1 if cat)\n",
    "    caches -- list of caches containing:\n",
    "                every cache of linear_activation_forward() with \"relu\" (it's caches[l], for l in range(L-1) i.e l = 0...L-2)\n",
    "                the cache of linear_activation_forward() with \"sigmoid\" (it's caches[L-1])\n",
    "    \n",
    "    Returns:\n",
    "    grads -- A dictionary with the gradients\n",
    "             grads[\"dA\" + str(l)] = ... \n",
    "             grads[\"dW\" + str(l)] = ...\n",
    "             grads[\"db\" + str(l)] = ... \n",
    "    \"\"\"\n",
    "    grads = {}\n",
    "    L = len(caches) # the number of layers\n",
    "    m = AL.shape[1]\n",
    "    Y = Y.reshape(AL.shape) # after this line, Y is the same shape as AL\n",
    "    \n",
    "    # Initializing the backpropagation\n",
    "    dAL = - (np.divide(Y, AL) - np.divide(1 - Y, 1 - AL)) \n",
    "    \n",
    "    # Lth layer (SIGMOID -> LINEAR) gradients. Inputs: \"dAL, current_cache\". Outputs: \"grads[\"dAL-1\"], grads[\"dWL\"], grads[\"dbL\"]\n",
    "    current_cache = caches[L-1]\n",
    "    grads[\"dA\" + str(L-1)], grads[\"dW\" + str(L)], grads[\"db\" + str(L)] = linear_activation_backward(dAL, current_cache, \"sigmoid\")\n",
    "    \n",
    "    # Loop from l=L-2 to l=0\n",
    "    for l in reversed(range(L-1)):\n",
    "        # lth layer: (RELU -> LINEAR) gradients.\n",
    "        # Inputs: \"grads[\"dA\" + str(l + 1)], current_cache\". Outputs: \"grads[\"dA\" + str(l)] , grads[\"dW\" + str(l + 1)] , grads[\"db\" + str(l + 1)] \n",
    "        current_cache = caches[l]\n",
    "        dA_prev_temp, dW_temp, db_temp = linear_activation_backward(grads[\"dA\" + str(l + 1)], current_cache, \"relu\")\n",
    "        grads[\"dA\" + str(l)] = dA_prev_temp\n",
    "        grads[\"dW\" + str(l + 1)] = dW_temp\n",
    "        grads[\"db\" + str(l + 1)] = db_temp\n",
    "\n",
    "    return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aquatic-stone",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-18T20:00:46.894513Z",
     "iopub.status.busy": "2021-04-18T20:00:46.893476Z",
     "iopub.status.idle": "2021-04-18T20:00:46.921661Z",
     "shell.execute_reply": "2021-04-18T20:00:46.920988Z"
    },
    "papermill": {
     "duration": 0.058609,
     "end_time": "2021-04-18T20:00:46.921822",
     "exception": false,
     "start_time": "2021-04-18T20:00:46.863213",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def update_parameters(parameters, grads, learning_rate):\n",
    "    \"\"\"\n",
    "    Update parameters using gradient descent\n",
    "    \n",
    "    Arguments:\n",
    "    parameters -- python dictionary containing your parameters \n",
    "    grads -- python dictionary containing your gradients, output of L_model_backward\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- python dictionary containing your updated parameters \n",
    "                  parameters[\"W\" + str(l)] = ... \n",
    "                  parameters[\"b\" + str(l)] = ...\n",
    "    \"\"\"\n",
    "    \n",
    "    L = len(parameters) // 2 # number of layers in the neural network\n",
    "\n",
    "    # Update rule for each parameter. Use a for loop.\n",
    "    for l in range(L):\n",
    "        parameters[\"W\" + str(l+1)] = parameters[\"W\" + str(l+1)] - learning_rate*(grads[\"dW\" + str(l+1)])\n",
    "        parameters[\"b\" + str(l+1)] = parameters[\"b\" + str(l+1)] - learning_rate*(grads[\"db\" + str(l+1)])\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "respiratory-weekly",
   "metadata": {
    "papermill": {
     "duration": 0.024005,
     "end_time": "2021-04-18T20:00:46.969618",
     "exception": false,
     "start_time": "2021-04-18T20:00:46.945613",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Below is a function for the whole model. It uses the previous implemented functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ranging-designer",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-18T20:00:47.027713Z",
     "iopub.status.busy": "2021-04-18T20:00:47.026922Z",
     "iopub.status.idle": "2021-04-18T20:00:47.055561Z",
     "shell.execute_reply": "2021-04-18T20:00:47.054817Z"
    },
    "papermill": {
     "duration": 0.062202,
     "end_time": "2021-04-18T20:00:47.055725",
     "exception": false,
     "start_time": "2021-04-18T20:00:46.993523",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def L_layer_model(X, Y, layers_dims, learning_rate, num_iterations, print_cost = False, print_plot = False):#lr was 0.009\n",
    "    \"\"\"\n",
    "    Implements a L-layer neural network: [LINEAR->RELU]*(L-1)->LINEAR->SIGMOID.\n",
    "    \n",
    "    Arguments:\n",
    "    X -- data, numpy array of shape (num_px * num_px * 3, number of examples)\n",
    "    Y -- true \"label\" vector (containing 0 if cat, 1 if non-cat), of shape (1, number of examples)\n",
    "    layers_dims -- list containing the input size and each layer size, of length (number of layers + 1).\n",
    "    learning_rate -- learning rate of the gradient descent update rule\n",
    "    num_iterations -- number of iterations of the optimization loop\n",
    "    print_cost -- if True, it prints the cost every 100 steps\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- parameters learnt by the model. They can then be used to predict.\n",
    "    \"\"\"\n",
    "    # keep track of cost\n",
    "    costs = []                         \n",
    "    \n",
    "    # Parameters initialization.\n",
    "    parameters = initialize_parameters_deep(layers_dims)\n",
    "        \n",
    "    # Loop (gradient descent)\n",
    "    for i in range(0, num_iterations):\n",
    "\n",
    "        # Forward propagation: [LINEAR -> RELU]*(L-1) -> LINEAR -> SIGMOID.\n",
    "        AL, caches = L_model_forward(X, parameters)\n",
    "        \n",
    "        # Compute cost.\n",
    "        cost = compute_cost(AL, Y)\n",
    "    \n",
    "        # Backward propagation.\n",
    "        grads = L_model_backward(AL, Y, caches)\n",
    " \n",
    "        # Update parameters.\n",
    "        parameters = update_parameters(parameters, grads, learning_rate)\n",
    "                \n",
    "        # Print the cost every 100 training example\n",
    "        if print_cost and i % 100 == 0:\n",
    "            print (\"Cost after iteration %i: %f\" %(i, cost))\n",
    "\n",
    "        costs.append(cost)\n",
    "    if print_plot:          \n",
    "        # plot the cost\n",
    "        plt.plot(np.squeeze(costs))\n",
    "        plt.ylabel('cost')\n",
    "        plt.xlabel('iterations (per hundreds)')\n",
    "        plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "        plt.show()\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "norwegian-retailer",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-18T20:00:47.111883Z",
     "iopub.status.busy": "2021-04-18T20:00:47.111182Z",
     "iopub.status.idle": "2021-04-18T20:00:47.139547Z",
     "shell.execute_reply": "2021-04-18T20:00:47.138805Z"
    },
    "papermill": {
     "duration": 0.060166,
     "end_time": "2021-04-18T20:00:47.139702",
     "exception": false,
     "start_time": "2021-04-18T20:00:47.079536",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict(X, y, parameters):\n",
    "    \"\"\"\n",
    "    This function is used to predict the results of a  L-layer neural network.\n",
    "    \n",
    "    Arguments:\n",
    "    X -- data set of examples you would like to label\n",
    "    parameters -- parameters of the trained model\n",
    "    \n",
    "    Returns:\n",
    "    p -- predictions for the given dataset X\n",
    "    \"\"\"\n",
    "    \n",
    "    m = X.shape[1]\n",
    "    n = len(parameters) // 2 # number of layers in the neural network\n",
    "    p = np.zeros((1,m))\n",
    "    \n",
    "    # Forward propagation\n",
    "    probas, caches = L_model_forward(X, parameters)\n",
    "\n",
    "    \n",
    "    # convert probas to 0/1 predictions\n",
    "    for i in range(0, probas.shape[1]):\n",
    "        if probas[0,i] > 0.5:\n",
    "            p[0,i] = 1\n",
    "        else:\n",
    "            p[0,i] = 0\n",
    "    \n",
    "    accuracy = np.sum((p == y)/m)\n",
    "    \n",
    "    #print results\n",
    "    #print(\"Accuracy: \"  + str(accuracy))\n",
    "        \n",
    "    return accuracy, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "blank-internship",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-18T20:00:47.197301Z",
     "iopub.status.busy": "2021-04-18T20:00:47.195689Z",
     "iopub.status.idle": "2021-04-18T20:00:47.233699Z",
     "shell.execute_reply": "2021-04-18T20:00:47.233111Z"
    },
    "papermill": {
     "duration": 0.070202,
     "end_time": "2021-04-18T20:00:47.233849",
     "exception": false,
     "start_time": "2021-04-18T20:00:47.163647",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict_for_test(X, parameters):\n",
    "    \"\"\"\n",
    "    This function is used to predict the results of a  L-layer neural network.\n",
    "    \n",
    "    Arguments:\n",
    "    X -- data set of examples you would like to label\n",
    "    parameters -- parameters of the trained model\n",
    "    \n",
    "    Returns:\n",
    "    p -- predictions for the given dataset X\n",
    "    \"\"\"\n",
    "    \n",
    "    m = X.shape[1]\n",
    "    n = len(parameters) // 2 # number of layers in the neural network\n",
    "    p = np.zeros((1,m))\n",
    "    \n",
    "    # Forward propagation\n",
    "    probas, caches = L_model_forward(X, parameters)\n",
    "\n",
    "    \n",
    "    # convert probas to 0/1 predictions\n",
    "    for i in range(0, probas.shape[1]):\n",
    "        if probas[0,i] > 0.5:\n",
    "            p[0,i] = 1\n",
    "        else:\n",
    "            p[0,i] = 0\n",
    "            \n",
    "    return p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tropical-glenn",
   "metadata": {
    "papermill": {
     "duration": 0.03008,
     "end_time": "2021-04-18T20:00:47.293961",
     "exception": false,
     "start_time": "2021-04-18T20:00:47.263881",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Function to test best dimentions and learning rate combinations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "institutional-extra",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-18T20:00:47.356346Z",
     "iopub.status.busy": "2021-04-18T20:00:47.353854Z",
     "iopub.status.idle": "2021-04-18T20:00:47.385034Z",
     "shell.execute_reply": "2021-04-18T20:00:47.384462Z"
    },
    "papermill": {
     "duration": 0.064243,
     "end_time": "2021-04-18T20:00:47.385210",
     "exception": false,
     "start_time": "2021-04-18T20:00:47.320967",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluateHyper(inputLayer, evaluationIter,train_x, train_y):\n",
    "    #Declaring and Initializing the best hyperparameters\n",
    "    maxAccuracy = 0\n",
    "    best_lamb = 0\n",
    "    \n",
    "    AvgAccuracy = 0\n",
    "    accuracyList = []\n",
    "    best_dim = []\n",
    "    \n",
    "\n",
    "    #Specifing the values that we need to try\n",
    "    list_learning_Rate = [0.1, 0.3, 0.6, 0.9]\n",
    "    list_Dim = [[inputLayer, 5 , 3, 1],[inputLayer, 4 , 1],[inputLayer, 3 , 1],[inputLayer, 2 , 1],[inputLayer, 1]] \n",
    "\n",
    "    #Going through each of the combination to figure out the cost fuction that is the most stable and accurate\n",
    "    for lamb in list_learning_Rate:\n",
    "        for dim in list_Dim:\n",
    "            print(dim)\n",
    "            for i in range(evaluationIter):\n",
    "                parameters = L_layer_model(train_x, train_y, dim, learning_rate = lamb, num_iterations = 5000, print_cost = False, print_plot = False)\n",
    "                accuracy, predictions = predict(train_x_np, train_y_np, parameters)\n",
    "                accuracyList.append(accuracy)            \n",
    "            # plot the cost\n",
    "            plt.plot(np.squeeze(accuracyList))\n",
    "            plt.ylabel('Accuracy')\n",
    "            plt.xlabel('Iterations')\n",
    "            plt.title(\"Learning rate =\" + str(lamb) + \"  Dimentions: \" + str(dim))\n",
    "            plt.show()\n",
    "           \n",
    "            if(mean(accuracyList) > AvgAccuracy):\n",
    "                AvgAccuracy = mean(accuracyList)\n",
    "                best_lamb = lamb\n",
    "                best_dim = dim\n",
    "            accuracyList = []\n",
    "\n",
    "    print('maxAverageAccuracy: '+str(AvgAccuracy)+' best_lamb: '+str(best_lamb)+' best_dim: '+str(best_dim))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "premier-function",
   "metadata": {
    "papermill": {
     "duration": 0.023837,
     "end_time": "2021-04-18T20:00:47.433383",
     "exception": false,
     "start_time": "2021-04-18T20:00:47.409546",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **======================= THE DEEP NEURAL NETWORK ==========================**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "trained-diving",
   "metadata": {
    "papermill": {
     "duration": 0.023593,
     "end_time": "2021-04-18T20:00:47.481262",
     "exception": false,
     "start_time": "2021-04-18T20:00:47.457669",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Loading training and testing data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "refined-restriction",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-18T20:00:47.535419Z",
     "iopub.status.busy": "2021-04-18T20:00:47.534523Z",
     "iopub.status.idle": "2021-04-18T20:00:47.614095Z",
     "shell.execute_reply": "2021-04-18T20:00:47.613524Z"
    },
    "papermill": {
     "duration": 0.10902,
     "end_time": "2021-04-18T20:00:47.614243",
     "exception": false,
     "start_time": "2021-04-18T20:00:47.505223",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Moran, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330877</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>McCarthy, Mr. Timothy J</td>\n",
       "      <td>male</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17463</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>E46</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Palsson, Master. Gosta Leonard</td>\n",
       "      <td>male</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>349909</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)</td>\n",
       "      <td>female</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>347742</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Nasser, Mrs. Nicholas (Adele Achem)</td>\n",
       "      <td>female</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>237736</td>\n",
       "      <td>30.0708</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "5            6         0       3   \n",
       "6            7         0       1   \n",
       "7            8         0       3   \n",
       "8            9         1       3   \n",
       "9           10         1       2   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "5                                   Moran, Mr. James    male   NaN      0   \n",
       "6                            McCarthy, Mr. Timothy J    male  54.0      0   \n",
       "7                     Palsson, Master. Gosta Leonard    male   2.0      3   \n",
       "8  Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)  female  27.0      0   \n",
       "9                Nasser, Mrs. Nicholas (Adele Achem)  female  14.0      1   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  \n",
       "5      0            330877   8.4583   NaN        Q  \n",
       "6      0             17463  51.8625   E46        S  \n",
       "7      1            349909  21.0750   NaN        S  \n",
       "8      2            347742  11.1333   NaN        S  \n",
       "9      0            237736  30.0708   NaN        C  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Loading the train data into variables\n",
    "train_data = pd.read_csv(\"/kaggle/input/titanic/train.csv\")\n",
    "train_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "multiple-sleeve",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-18T20:00:47.668852Z",
     "iopub.status.busy": "2021-04-18T20:00:47.668250Z",
     "iopub.status.idle": "2021-04-18T20:00:47.720714Z",
     "shell.execute_reply": "2021-04-18T20:00:47.720033Z"
    },
    "papermill": {
     "duration": 0.081545,
     "end_time": "2021-04-18T20:00:47.720859",
     "exception": false,
     "start_time": "2021-04-18T20:00:47.639314",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>897</td>\n",
       "      <td>3</td>\n",
       "      <td>Svensson, Mr. Johan Cervin</td>\n",
       "      <td>male</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7538</td>\n",
       "      <td>9.2250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>898</td>\n",
       "      <td>3</td>\n",
       "      <td>Connolly, Miss. Kate</td>\n",
       "      <td>female</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330972</td>\n",
       "      <td>7.6292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>899</td>\n",
       "      <td>2</td>\n",
       "      <td>Caldwell, Mr. Albert Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>248738</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>900</td>\n",
       "      <td>3</td>\n",
       "      <td>Abrahim, Mrs. Joseph (Sophie Halaut Easu)</td>\n",
       "      <td>female</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2657</td>\n",
       "      <td>7.2292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>901</td>\n",
       "      <td>3</td>\n",
       "      <td>Davies, Mr. John Samuel</td>\n",
       "      <td>male</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>A/4 48871</td>\n",
       "      <td>24.1500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                          Name     Sex  \\\n",
       "0          892       3                              Kelly, Mr. James    male   \n",
       "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
       "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
       "3          895       3                              Wirz, Mr. Albert    male   \n",
       "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
       "5          897       3                    Svensson, Mr. Johan Cervin    male   \n",
       "6          898       3                          Connolly, Miss. Kate  female   \n",
       "7          899       2                  Caldwell, Mr. Albert Francis    male   \n",
       "8          900       3     Abrahim, Mrs. Joseph (Sophie Halaut Easu)  female   \n",
       "9          901       3                       Davies, Mr. John Samuel    male   \n",
       "\n",
       "    Age  SibSp  Parch     Ticket     Fare Cabin Embarked  \n",
       "0  34.5      0      0     330911   7.8292   NaN        Q  \n",
       "1  47.0      1      0     363272   7.0000   NaN        S  \n",
       "2  62.0      0      0     240276   9.6875   NaN        Q  \n",
       "3  27.0      0      0     315154   8.6625   NaN        S  \n",
       "4  22.0      1      1    3101298  12.2875   NaN        S  \n",
       "5  14.0      0      0       7538   9.2250   NaN        S  \n",
       "6  30.0      0      0     330972   7.6292   NaN        Q  \n",
       "7  26.0      1      1     248738  29.0000   NaN        S  \n",
       "8  18.0      0      0       2657   7.2292   NaN        C  \n",
       "9  21.0      2      0  A/4 48871  24.1500   NaN        S  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Loading the test data into variables\n",
    "test_data = pd.read_csv(\"/kaggle/input/titanic/test.csv\")\n",
    "test_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "civil-adjustment",
   "metadata": {
    "papermill": {
     "duration": 0.025275,
     "end_time": "2021-04-18T20:00:47.771926",
     "exception": false,
     "start_time": "2021-04-18T20:00:47.746651",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Feature extraction, Cleaning, and normalizing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aquatic-situation",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-18T20:00:47.835231Z",
     "iopub.status.busy": "2021-04-18T20:00:47.834141Z",
     "iopub.status.idle": "2021-04-18T20:00:47.933455Z",
     "shell.execute_reply": "2021-04-18T20:00:47.934017Z"
    },
    "papermill": {
     "duration": 0.136442,
     "end_time": "2021-04-18T20:00:47.934236",
     "exception": false,
     "start_time": "2021-04-18T20:00:47.797794",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.33333333 1.         ... 1.         0.33333333 1.        ]\n",
      " [0.275      0.475      0.325      ... 0.35       0.325      0.4       ]\n",
      " [1.         1.         0.         ... 1.         0.         0.        ]\n",
      " ...\n",
      " [0.         1.         0.         ... 0.         1.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         1.        ]\n",
      " [1.         0.         1.         ... 1.         0.         0.        ]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>881</th>\n",
       "      <th>882</th>\n",
       "      <th>883</th>\n",
       "      <th>884</th>\n",
       "      <th>885</th>\n",
       "      <th>886</th>\n",
       "      <th>887</th>\n",
       "      <th>888</th>\n",
       "      <th>889</th>\n",
       "      <th>890</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Pclass</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>0.275000</td>\n",
       "      <td>0.475000</td>\n",
       "      <td>0.325000</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.35000</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.337500</td>\n",
       "      <td>0.175000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.412500</td>\n",
       "      <td>0.275000</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.487500</td>\n",
       "      <td>0.337500</td>\n",
       "      <td>0.237500</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.325000</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SibSp</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parch</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fare</th>\n",
       "      <td>0.014151</td>\n",
       "      <td>0.139136</td>\n",
       "      <td>0.015469</td>\n",
       "      <td>0.103644</td>\n",
       "      <td>0.015713</td>\n",
       "      <td>0.01651</td>\n",
       "      <td>0.101229</td>\n",
       "      <td>0.041136</td>\n",
       "      <td>0.021731</td>\n",
       "      <td>0.058694</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015412</td>\n",
       "      <td>0.020527</td>\n",
       "      <td>0.020495</td>\n",
       "      <td>0.013761</td>\n",
       "      <td>0.056848</td>\n",
       "      <td>0.025374</td>\n",
       "      <td>0.058556</td>\n",
       "      <td>0.045771</td>\n",
       "      <td>0.058556</td>\n",
       "      <td>0.015127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex_female</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex_male</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Embarked_C</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Embarked_Q</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Embarked_S</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows  891 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0         1         2         3         4        5    \\\n",
       "Pclass      1.000000  0.333333  1.000000  0.333333  1.000000  1.00000   \n",
       "Age         0.275000  0.475000  0.325000  0.437500  0.437500  0.35000   \n",
       "SibSp       1.000000  1.000000  0.000000  1.000000  0.000000  0.00000   \n",
       "Parch       0.000000  0.000000  0.000000  0.000000  0.000000  0.00000   \n",
       "Fare        0.014151  0.139136  0.015469  0.103644  0.015713  0.01651   \n",
       "Sex_female  0.000000  1.000000  1.000000  1.000000  0.000000  0.00000   \n",
       "Sex_male    1.000000  0.000000  0.000000  0.000000  1.000000  1.00000   \n",
       "Embarked_C  0.000000  1.000000  0.000000  0.000000  0.000000  0.00000   \n",
       "Embarked_Q  0.000000  0.000000  0.000000  0.000000  0.000000  1.00000   \n",
       "Embarked_S  1.000000  0.000000  1.000000  1.000000  1.000000  0.00000   \n",
       "\n",
       "                 6         7         8         9    ...       881       882  \\\n",
       "Pclass      0.333333  1.000000  1.000000  0.666667  ...  1.000000  1.000000   \n",
       "Age         0.675000  0.025000  0.337500  0.175000  ...  0.412500  0.275000   \n",
       "SibSp       0.000000  3.000000  0.000000  1.000000  ...  0.000000  0.000000   \n",
       "Parch       0.000000  1.000000  2.000000  0.000000  ...  0.000000  0.000000   \n",
       "Fare        0.101229  0.041136  0.021731  0.058694  ...  0.015412  0.020527   \n",
       "Sex_female  0.000000  0.000000  1.000000  1.000000  ...  0.000000  1.000000   \n",
       "Sex_male    1.000000  1.000000  0.000000  0.000000  ...  1.000000  0.000000   \n",
       "Embarked_C  0.000000  0.000000  0.000000  1.000000  ...  0.000000  0.000000   \n",
       "Embarked_Q  0.000000  0.000000  0.000000  0.000000  ...  0.000000  0.000000   \n",
       "Embarked_S  1.000000  1.000000  1.000000  0.000000  ...  1.000000  1.000000   \n",
       "\n",
       "                 883       884       885       886       887       888  \\\n",
       "Pclass      0.666667  1.000000  1.000000  0.666667  0.333333  1.000000   \n",
       "Age         0.350000  0.312500  0.487500  0.337500  0.237500  0.350000   \n",
       "SibSp       0.000000  0.000000  0.000000  0.000000  0.000000  1.000000   \n",
       "Parch       0.000000  0.000000  5.000000  0.000000  0.000000  2.000000   \n",
       "Fare        0.020495  0.013761  0.056848  0.025374  0.058556  0.045771   \n",
       "Sex_female  0.000000  0.000000  1.000000  0.000000  1.000000  1.000000   \n",
       "Sex_male    1.000000  1.000000  0.000000  1.000000  0.000000  0.000000   \n",
       "Embarked_C  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "Embarked_Q  0.000000  0.000000  1.000000  0.000000  0.000000  0.000000   \n",
       "Embarked_S  1.000000  1.000000  0.000000  1.000000  1.000000  1.000000   \n",
       "\n",
       "                 889       890  \n",
       "Pclass      0.333333  1.000000  \n",
       "Age         0.325000  0.400000  \n",
       "SibSp       0.000000  0.000000  \n",
       "Parch       0.000000  0.000000  \n",
       "Fare        0.058556  0.015127  \n",
       "Sex_female  0.000000  0.000000  \n",
       "Sex_male    1.000000  1.000000  \n",
       "Embarked_C  1.000000  0.000000  \n",
       "Embarked_Q  0.000000  1.000000  \n",
       "Embarked_S  0.000000  0.000000  \n",
       "\n",
       "[10 rows x 891 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Loading feature data into train_x\n",
    "features = [\"Pclass\", \"Age\", \"Sex\", \"SibSp\", \"Parch\", \"Fare\", \"Embarked\"]\n",
    "training_data = pd.get_dummies(train_data[features])\n",
    "\n",
    "#normalizing the features\n",
    "training_data[\"Age\"] = training_data[\"Age\"].divide(training_data[\"Age\"].max())\n",
    "training_data[\"Fare\"] = training_data[\"Fare\"].divide(training_data[\"Fare\"].max())\n",
    "training_data[\"Pclass\"] = training_data[\"Pclass\"].divide(training_data[\"Pclass\"].max())\n",
    "\n",
    "#Replacing NaN values with the median of the column\n",
    "training_data['Pclass'].fillna(value = training_data['Pclass'].median(), inplace=True)\n",
    "training_data['Age'].fillna(value = training_data['Age'].median(), inplace=True)\n",
    "training_data['Sex_female'].fillna(value = training_data['Sex_female'].median(), inplace=True)\n",
    "training_data['Sex_male'].fillna(value = training_data['Sex_male'].median(), inplace=True)\n",
    "training_data['SibSp'].fillna(value = training_data['SibSp'].median(), inplace=True)\n",
    "training_data['Parch'].fillna(value = training_data['Parch'].median(), inplace=True)\n",
    "training_data['Fare'].fillna(value = training_data['Fare'].median(), inplace=True)\n",
    "\n",
    "train_x = training_data.transpose()\n",
    "\n",
    "#Converting the test data from a dataframe to a numpy array\n",
    "train_x_np = train_x.to_numpy()\n",
    "print(train_x_np)\n",
    "\n",
    "train_x.head(100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "obvious-meditation",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-18T20:00:48.000200Z",
     "iopub.status.busy": "2021-04-18T20:00:47.999155Z",
     "iopub.status.idle": "2021-04-18T20:00:48.071591Z",
     "shell.execute_reply": "2021-04-18T20:00:48.070953Z"
    },
    "papermill": {
     "duration": 0.109922,
     "end_time": "2021-04-18T20:00:48.071738",
     "exception": false,
     "start_time": "2021-04-18T20:00:47.961816",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         1.         0.66666667 ... 1.         1.         1.        ]\n",
      " [0.45394737 0.61842105 0.81578947 ... 0.50657895 0.35526316 0.35526316]\n",
      " [0.         1.         0.         ... 0.         0.         1.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.         1.        ]\n",
      " [1.         0.         1.         ... 0.         0.         0.        ]\n",
      " [0.         1.         0.         ... 1.         1.         0.        ]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>408</th>\n",
       "      <th>409</th>\n",
       "      <th>410</th>\n",
       "      <th>411</th>\n",
       "      <th>412</th>\n",
       "      <th>413</th>\n",
       "      <th>414</th>\n",
       "      <th>415</th>\n",
       "      <th>416</th>\n",
       "      <th>417</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Pclass</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>0.453947</td>\n",
       "      <td>0.618421</td>\n",
       "      <td>0.815789</td>\n",
       "      <td>0.355263</td>\n",
       "      <td>0.289474</td>\n",
       "      <td>0.184211</td>\n",
       "      <td>0.394737</td>\n",
       "      <td>0.342105</td>\n",
       "      <td>0.236842</td>\n",
       "      <td>0.276316</td>\n",
       "      <td>...</td>\n",
       "      <td>0.355263</td>\n",
       "      <td>0.039474</td>\n",
       "      <td>0.355263</td>\n",
       "      <td>0.486842</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.355263</td>\n",
       "      <td>0.513158</td>\n",
       "      <td>0.506579</td>\n",
       "      <td>0.355263</td>\n",
       "      <td>0.355263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SibSp</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parch</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fare</th>\n",
       "      <td>0.015282</td>\n",
       "      <td>0.013663</td>\n",
       "      <td>0.018909</td>\n",
       "      <td>0.016908</td>\n",
       "      <td>0.023984</td>\n",
       "      <td>0.018006</td>\n",
       "      <td>0.014891</td>\n",
       "      <td>0.056604</td>\n",
       "      <td>0.014110</td>\n",
       "      <td>0.047138</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015070</td>\n",
       "      <td>0.026887</td>\n",
       "      <td>0.015127</td>\n",
       "      <td>0.175668</td>\n",
       "      <td>0.015176</td>\n",
       "      <td>0.015713</td>\n",
       "      <td>0.212559</td>\n",
       "      <td>0.014151</td>\n",
       "      <td>0.015713</td>\n",
       "      <td>0.043640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex_female</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex_male</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Embarked_C</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Embarked_Q</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Embarked_S</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows  418 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0         1         2         3         4         5    \\\n",
       "Pclass      1.000000  1.000000  0.666667  1.000000  1.000000  1.000000   \n",
       "Age         0.453947  0.618421  0.815789  0.355263  0.289474  0.184211   \n",
       "SibSp       0.000000  1.000000  0.000000  0.000000  1.000000  0.000000   \n",
       "Parch       0.000000  0.000000  0.000000  0.000000  1.000000  0.000000   \n",
       "Fare        0.015282  0.013663  0.018909  0.016908  0.023984  0.018006   \n",
       "Sex_female  0.000000  1.000000  0.000000  0.000000  1.000000  0.000000   \n",
       "Sex_male    1.000000  0.000000  1.000000  1.000000  0.000000  1.000000   \n",
       "Embarked_C  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "Embarked_Q  1.000000  0.000000  1.000000  0.000000  0.000000  0.000000   \n",
       "Embarked_S  0.000000  1.000000  0.000000  1.000000  1.000000  1.000000   \n",
       "\n",
       "                 6         7         8         9    ...       408       409  \\\n",
       "Pclass      1.000000  0.666667  1.000000  1.000000  ...  1.000000  1.000000   \n",
       "Age         0.394737  0.342105  0.236842  0.276316  ...  0.355263  0.039474   \n",
       "SibSp       0.000000  1.000000  0.000000  2.000000  ...  0.000000  1.000000   \n",
       "Parch       0.000000  1.000000  0.000000  0.000000  ...  0.000000  1.000000   \n",
       "Fare        0.014891  0.056604  0.014110  0.047138  ...  0.015070  0.026887   \n",
       "Sex_female  1.000000  0.000000  1.000000  0.000000  ...  1.000000  1.000000   \n",
       "Sex_male    0.000000  1.000000  0.000000  1.000000  ...  0.000000  0.000000   \n",
       "Embarked_C  0.000000  0.000000  1.000000  0.000000  ...  0.000000  0.000000   \n",
       "Embarked_Q  1.000000  0.000000  0.000000  0.000000  ...  1.000000  0.000000   \n",
       "Embarked_S  0.000000  1.000000  0.000000  1.000000  ...  0.000000  1.000000   \n",
       "\n",
       "                 410       411       412       413       414       415  \\\n",
       "Pclass      1.000000  0.333333  1.000000  1.000000  0.333333  1.000000   \n",
       "Age         0.355263  0.486842  0.368421  0.355263  0.513158  0.506579   \n",
       "SibSp       0.000000  1.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "Parch       0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "Fare        0.015127  0.175668  0.015176  0.015713  0.212559  0.014151   \n",
       "Sex_female  1.000000  1.000000  1.000000  0.000000  1.000000  0.000000   \n",
       "Sex_male    0.000000  0.000000  0.000000  1.000000  0.000000  1.000000   \n",
       "Embarked_C  0.000000  0.000000  0.000000  0.000000  1.000000  0.000000   \n",
       "Embarked_Q  1.000000  1.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "Embarked_S  0.000000  0.000000  1.000000  1.000000  0.000000  1.000000   \n",
       "\n",
       "                 416       417  \n",
       "Pclass      1.000000  1.000000  \n",
       "Age         0.355263  0.355263  \n",
       "SibSp       0.000000  1.000000  \n",
       "Parch       0.000000  1.000000  \n",
       "Fare        0.015713  0.043640  \n",
       "Sex_female  0.000000  0.000000  \n",
       "Sex_male    1.000000  1.000000  \n",
       "Embarked_C  0.000000  1.000000  \n",
       "Embarked_Q  0.000000  0.000000  \n",
       "Embarked_S  1.000000  0.000000  \n",
       "\n",
       "[10 rows x 418 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Loading feature data into test_x\n",
    "features = [\"Pclass\", \"Age\", \"Sex\", \"SibSp\", \"Parch\", \"Fare\", \"Embarked\"]\n",
    "testing_data = pd.get_dummies(test_data[features])\n",
    "\n",
    "\n",
    "#normalizing the features\n",
    "testing_data[\"Age\"] = testing_data[\"Age\"].divide(testing_data[\"Age\"].max())\n",
    "testing_data[\"Fare\"] = testing_data[\"Fare\"].divide(testing_data[\"Fare\"].max())\n",
    "testing_data[\"Pclass\"] = testing_data[\"Pclass\"].divide(testing_data[\"Pclass\"].max())\n",
    "\n",
    "#Replacing NaN values with the median of the column\n",
    "testing_data['Pclass'].fillna(value = testing_data['Pclass'].median(), inplace=True)\n",
    "testing_data['Age'].fillna(value = testing_data['Age'].median(), inplace=True)\n",
    "testing_data['Sex_female'].fillna(value = testing_data['Sex_female'].median(), inplace=True)\n",
    "testing_data['Sex_male'].fillna(value = testing_data['Sex_male'].median(), inplace=True)\n",
    "testing_data['SibSp'].fillna(value = testing_data['SibSp'].median(), inplace=True)\n",
    "testing_data['Parch'].fillna(value = testing_data['Parch'].median(), inplace=True)\n",
    "testing_data['Fare'].fillna(value = testing_data['Fare'].median(), inplace=True)\n",
    "\n",
    "test_x = testing_data.transpose()\n",
    "\n",
    "#Converting the test data from a dataframe to a numpy array\n",
    "test_x_np = test_x.to_numpy()\n",
    "print(test_x_np)\n",
    "\n",
    "test_x.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "attached-tackle",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-18T20:00:48.136531Z",
     "iopub.status.busy": "2021-04-18T20:00:48.135476Z",
     "iopub.status.idle": "2021-04-18T20:00:48.187401Z",
     "shell.execute_reply": "2021-04-18T20:00:48.186325Z"
    },
    "papermill": {
     "duration": 0.087518,
     "end_time": "2021-04-18T20:00:48.187578",
     "exception": false,
     "start_time": "2021-04-18T20:00:48.100060",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 1 1 0 0 0 0 1 1 1 1 0 0 0 1 0 1 0 1 0 1 1 1 0 1 0 0 1 0 0 1 1 0 0 0\n",
      "  1 0 0 1 0 0 0 1 1 0 0 1 0 0 0 0 1 1 0 1 1 0 1 0 0 1 0 0 0 1 1 0 1 0 0 0\n",
      "  0 0 1 0 0 0 1 1 0 1 1 0 1 1 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 1\n",
      "  0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 1 0 0 0 0 1 0 0 1 0 0 0 0 1 1 0\n",
      "  0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      "  0 0 0 1 1 0 1 1 0 0 1 0 1 1 1 1 0 0 1 0 0 0 0 0 1 0 0 1 1 1 0 1 0 0 0 1\n",
      "  1 0 1 0 1 0 0 0 1 0 1 0 0 0 1 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 1 1 0 0 0\n",
      "  0 0 0 1 1 1 1 1 0 1 0 0 0 0 0 1 1 1 0 1 1 0 1 1 0 0 0 1 0 0 0 1 0 0 1 0\n",
      "  1 1 1 1 0 0 0 0 0 0 1 1 1 1 0 1 0 1 1 1 0 1 1 1 0 0 0 1 1 0 1 1 0 0 1 1\n",
      "  0 1 0 1 1 1 1 0 0 0 1 0 0 1 1 0 1 1 0 0 0 1 1 1 1 0 0 0 0 0 0 0 1 0 1 1\n",
      "  0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 1 1 0 0 0 1 1 0 1 0 0 0 1 0 1 1 1 0 1 1 0\n",
      "  0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 1 1 0 0 0 0 0 0 0 0 1 1 0 1 1 1\n",
      "  1 0 0 1 0 1 0 0 1 0 0 1 1 1 1 1 1 1 0 0 0 1 0 1 0 1 1 0 1 0 0 0 0 0 0 0\n",
      "  0 1 0 0 1 1 0 0 0 0 0 1 0 0 0 1 1 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      "  1 0 1 1 0 1 1 0 1 1 0 0 1 0 1 0 1 0 0 1 0 0 1 0 0 0 1 0 0 1 0 1 0 1 0 1\n",
      "  1 0 0 1 0 0 1 1 0 1 1 0 0 1 1 0 1 0 1 1 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0\n",
      "  1 1 0 1 1 1 0 0 0 1 0 1 0 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 0 0 1 1 1 0 0\n",
      "  1 0 0 1 0 0 1 0 0 1 1 0 0 0 0 1 0 0 1 0 1 0 0 1 0 0 0 0 0 1 0 1 1 1 0 1\n",
      "  0 1 0 1 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 1 0 0 1 0 0 0 1 0 1 0 1 0 0\n",
      "  0 0 0 0 0 1 1 1 1 0 0 0 0 1 0 0 1 1 0 0 0 0 1 1 1 1 1 0 1 0 0 0 1 1 0 0\n",
      "  1 0 0 0 1 0 1 1 0 0 1 0 0 0 0 0 0 1 0 0 1 0 1 0 1 0 0 1 0 0 1 1 0 0 1 1\n",
      "  0 0 0 1 0 0 1 1 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 1 1 1 0 0 0 0 1 0 1 0 0 0\n",
      "  0 0 0 0 1 1 0 0 0 1 1 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 1\n",
      "  1 1 1 1 0 0 0 1 0 0 1 1 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 1 1 1 1 0 0 0 1 0\n",
      "  0 1 1 0 0 1 0 1 0 0 1 1 0 0 0 1 1 0 0 0 0 0 0 1 0 1 0]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>881</th>\n",
       "      <th>882</th>\n",
       "      <th>883</th>\n",
       "      <th>884</th>\n",
       "      <th>885</th>\n",
       "      <th>886</th>\n",
       "      <th>887</th>\n",
       "      <th>888</th>\n",
       "      <th>889</th>\n",
       "      <th>890</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Survived</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows  891 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0    1    2    3    4    5    6    7    8    9    ...  881  882  \\\n",
       "Survived    0    1    1    1    0    0    0    0    1    1  ...    0    0   \n",
       "\n",
       "          883  884  885  886  887  888  889  890  \n",
       "Survived    0    0    0    0    1    0    1    0  \n",
       "\n",
       "[1 rows x 891 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Loading survival data into train_y\n",
    "train_y = train_data[['Survived']] \n",
    "train_y = train_y.transpose()\n",
    "\n",
    "train_y_np = train_y.to_numpy()\n",
    "print(train_y_np)\n",
    "\n",
    "train_y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "racial-mineral",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-18T20:00:48.256282Z",
     "iopub.status.busy": "2021-04-18T20:00:48.255277Z",
     "iopub.status.idle": "2021-04-18T20:00:51.520177Z",
     "shell.execute_reply": "2021-04-18T20:00:51.519524Z"
    },
    "papermill": {
     "duration": 3.303203,
     "end_time": "2021-04-18T20:00:51.520343",
     "exception": false,
     "start_time": "2021-04-18T20:00:48.217140",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 0.741002\n",
      "Cost after iteration 100: 0.543463\n",
      "Cost after iteration 200: 0.505117\n",
      "Cost after iteration 300: 0.484454\n",
      "Cost after iteration 400: 0.472888\n",
      "Cost after iteration 500: 0.464982\n",
      "Cost after iteration 600: 0.456415\n",
      "Cost after iteration 700: 0.451788\n",
      "Cost after iteration 800: 0.448311\n",
      "Cost after iteration 900: 0.444324\n",
      "Cost after iteration 1000: 0.440597\n",
      "Cost after iteration 1100: 0.437020\n",
      "Cost after iteration 1200: 0.432804\n",
      "Cost after iteration 1300: 0.428883\n",
      "Cost after iteration 1400: 0.426352\n",
      "Cost after iteration 1500: 0.424393\n",
      "Cost after iteration 1600: 0.422783\n",
      "Cost after iteration 1700: 0.421229\n",
      "Cost after iteration 1800: 0.419683\n",
      "Cost after iteration 1900: 0.418300\n",
      "Cost after iteration 2000: 0.417119\n",
      "Cost after iteration 2100: 0.415594\n",
      "Cost after iteration 2200: 0.414348\n",
      "Cost after iteration 2300: 0.413248\n",
      "Cost after iteration 2400: 0.412122\n",
      "Cost after iteration 2500: 0.411079\n",
      "Cost after iteration 2600: 0.410166\n",
      "Cost after iteration 2700: 0.409262\n",
      "Cost after iteration 2800: 0.408441\n",
      "Cost after iteration 2900: 0.407733\n",
      "Cost after iteration 3000: 0.407083\n",
      "Cost after iteration 3100: 0.406432\n",
      "Cost after iteration 3200: 0.405819\n",
      "Cost after iteration 3300: 0.405274\n",
      "Cost after iteration 3400: 0.404854\n",
      "Cost after iteration 3500: 0.404404\n",
      "Cost after iteration 3600: 0.403883\n",
      "Cost after iteration 3700: 0.403285\n",
      "Cost after iteration 3800: 0.402810\n",
      "Cost after iteration 3900: 0.402411\n",
      "Cost after iteration 4000: 0.402007\n",
      "Cost after iteration 4100: 0.401686\n",
      "Cost after iteration 4200: 0.401399\n",
      "Cost after iteration 4300: 0.400942\n",
      "Cost after iteration 4400: 0.400278\n",
      "Cost after iteration 4500: 0.399326\n",
      "Cost after iteration 4600: 0.398737\n",
      "Cost after iteration 4700: 0.398388\n",
      "Cost after iteration 4800: 0.398096\n",
      "Cost after iteration 4900: 0.397835\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVAAAAEWCAYAAAAw6c+oAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8+yak3AAAACXBIWXMAAAsTAAALEwEAmpwYAAAqiklEQVR4nO3deZhcVZ3/8fenqvc1nXRn3yEQQDZpWUQYXICgDjCCGphx0BmNOoPM6Iw88HN+DIPj/HAffWQGUREXJCAuEyEKKCAMEkizJJCEhJCQfemks3R6X76/P+7pUCmqO93VXV3dXd/X89yn7j13+55K5dvnbufKzHDOOTdwsWwH4Jxzo5UnUOecS5MnUOecS5MnUOecS5MnUOecS5MnUOecS5MnUDdiSTpP0tpsx+FcbzyBupQkvS7pPdmMwcyeNLPjsxlDD0kXSNo6TPt6t6RXJDVLekzSrD6W/aKklyR1Srp5OOJzb/AE6rJGUjzbMQAoMiL+L0iqBn4J/F9gPFAH3NvHKuuB64EHMx+dSzYifjRu9JAUk3SDpNck7ZV0n6TxCfN/LmmnpAOSnpB0UsK8uyT9t6SlkpqAd4aW7j9LWhnWuVdSUVj+iFZfX8uG+ddL2iFpu6SPSzJJx/ZSj8clfUnSU0AzMFfSxyStkdQoaYOkT4ZlS4HfAlMlHQrD1KN9F2n6ALDKzH5uZq3AzcCpkuanWtjMfmRmvwUaB7lflwZPoG6gPgNcDvwZMBXYB9yWMP+3wDxgIvA8cHfS+lcDXwLKgf8NZR8CFgBzgFOAj/ax/5TLSloAfA54D3AscEE/6vIRYFGIZROwG3g/UAF8DPimpLeaWRNwCbDdzMrCsL0f38VhkmZK2t/HcHVY9CRgRc96Yd+vhXI3wuRlOwA36nwKuNbMtgKE826bJX3EzDrN7M6eBcO8fZIqzexAKP4fM3sqjLdKAvh2SEhI+g1wWh/7723ZDwE/NLNVCfv+y6PU5a6e5YPEw+A/SnoYOI/oD0EqfX4XiQua2WZg3FHiASgD6pPKDhAleTfCeAvUDdQs4Fc9LSdgDdAFTJIUl3RrOKQ9CLwe1qlOWH9Lim3uTBhvJkoivelt2alJ2061n2RHLCPpEknLJDWEur2XI2NP1ut30Y999+YQUQs4UQV+iD4ieQJ1A7UFuMTMxiUMRWa2jejw/DKiw+hKYHZYRwnrZ6r7rx3A9ITpGf1Y53AskgqBXwBfAyaZ2ThgKW/Eniruvr6LI4RD+EN9DD2t5VXAqQnrlQLHhHI3wngCdX3Jl1SUMOQBtwNf6rm1RlKNpMvC8uVAG7AXKAH+YxhjvQ/4mKQTJJUQXcUeiAKgkOjwuVPSJcBFCfN3ARMkVSaU9fVdHMHMNiecP0019Jwr/hXwFklXhAtkNwErzeyVVNuVlB+WiwF54d9pRNzdkAs8gbq+LAVaEoabgW8BS4CHJTUCy4CzwvI/JroYsw1YHeYNi3Al+tvAY0S39vTsu62f6zcC1xEl4n1EreklCfNfAe4BNoRD9qn0/V2kW4964AqiC237wvYW9syXdLuk2xNW+R7Rv81VwBfC+EcGE4PrP3mHym4sknQC8DJQmHxBx7mh4i1QN2ZI+gtJhZKqgC8Dv/Hk6TLJE6gbSz5JdC/na0RXwz+d3XDcWOeH8M45lyZvgTrnXJrGzJNI1dXVNnv27GyH4ZwbY5577rk9ZlaTat6YSaCzZ8+mrq4u22E458YYSZt6m5fRQ3hJCyStlbRe0g0p5n9T0othWBceh+uZ15Uwb0nyus45l20Za4GGpyFuAy4EtgLLJS0xs9U9y5jZZxOW/wxwesImWszstEzF55xzg5XJFuiZwHoz22Bm7cBioueke3MV0ZMezjk3KmQygU7jyN5utoayNwnPEs8BHk0oLpJUF3rHubyX9RaFZerq65N7AHPOucwaKbcxLQTuN7OuhLJZZlZL9Ezyf0o6JnklM7vDzGrNrLamJuVFMuecy5hMJtBtHNml2PRQlspCkg7fe7oEM7MNwOMceX7UOeeyLpMJdDkwT9IcSQVESfJNV9PDu16qgKcTyqpC/4w9L9k6l6h3H+ecGzEylkBDJw7XAg8R9dR9n5mtknSLpEsTFl0ILLYjnyk9AaiTtIKoe7JbE6/eD4XfvbyT7z2xYSg36ZzLMRm9kd7MlhL1KZlYdlPS9M0p1vsTcHImY/vDml08tX4Pnzh/biZ345wbw0bKRaRhJ0G396PinBuEnE2gMYlu74nKOTcIOZtAJWXs7WbOudyQwwkUvC9U59xg5GwCjQk8fzrnBiNnE6jwc6DOucHJ2QQaE34O1Dk3KDmbQCXR7fcxOecGIYcTqJ8Ddc4NTs4m0JjfxuScG6ScTaACv4jknBuUnE2gsZj8EN45Nyg5m0CjZ+E9gzrn0pe7CRRvgTrnBidnE2h0H6hnUOdc+nI2gXp3ds65wcrZBBqTvDMR59yg5GwCleQtUOfcoORuAg2f3gp1zqUrZxNoTFEK9fzpnEtXRhOopAWS1kpaL+mGFPO/KenFMKyTtD9h3jWSXg3DNUMfW/Tp94I659KVsbdySooDtwEXAluB5ZKWJL6e2Mw+m7D8Z4DTw/h44F+BWqJe554L6+4bqvhiIYF6+nTOpSuTLdAzgfVmtsHM2oHFwGV9LH8VcE8Yvxh4xMwaQtJ8BFgwlMEpNEG9BeqcS1cmE+g0YEvC9NZQ9iaSZgFzgEcHsq6kRZLqJNXV19cPKLieQ3jPn865dI2Ui0gLgfvNrGsgK5nZHWZWa2a1NTU1A9qhX0Ryzg1WJhPoNmBGwvT0UJbKQt44fB/oummJ+UUk59wgZTKBLgfmSZojqYAoSS5JXkjSfKAKeDqh+CHgIklVkqqAi0LZkOlpgXZ5AnXOpSljV+HNrFPStUSJLw7caWarJN0C1JlZTzJdCCy2hDvazaxB0heJkjDALWbWMJTx9VxEsu6h3KpzLpdkLIECmNlSYGlS2U1J0zf3su6dwJ2Zii3uh/DOuUEaKReRhl0s5rcxOecGJ2cT6Bv3gWY5EOfcqJWzCfTwk0jeAnXOpSmHE6i3QJ1zg5PDCTT69HOgzrl05WwC9WfhnXODlbMJ1B/ldM4NVg4n0OjTW6DOuXTlcAL1i0jOucHJ2QTqPdI75wYrZxPoG+dAPYE659KT8wnUD+Gdc+nK4QQaffohvHMuXTmbQA/fB+rd2Tnn0pSzCdRboM65wcrhBOo30jvnBid3E2ioubdAnXPpytkE6s/CO+cGK2cTqN/G5JwbrIwmUEkLJK2VtF7SDb0s8yFJqyWtkvSzhPIuSS+G4U1v8xws71DZOTdYGXupnKQ4cBtwIbAVWC5piZmtTlhmHnAjcK6Z7ZM0MWETLWZ2Wqbi8xaoc26wMtkCPRNYb2YbzKwdWAxclrTMJ4DbzGwfgJntzmA8R/Bn4Z1zg5XJBDoN2JIwvTWUJToOOE7SU5KWSVqQMK9IUl0ov3yog4v5RSTn3CBl9L3w/dz/POACYDrwhKSTzWw/MMvMtkmaCzwq6SUzey1xZUmLgEUAM2fOHNCO/T5Q59xgZbIFug2YkTA9PZQl2gosMbMOM9sIrCNKqJjZtvC5AXgcOD15B2Z2h5nVmlltTU3NgILzJ5Gcc4OVyQS6HJgnaY6kAmAhkHw1/ddErU8kVRMd0m+QVCWpMKH8XGA1Q8jfC++cG6yMHcKbWaeka4GHgDhwp5mtknQLUGdmS8K8iyStBrqAz5vZXklvB74rqZsoyd+aePV+KHgL1Dk3WBk9B2pmS4GlSWU3JYwb8LkwJC7zJ+DkTMbmHSo75wbLn0Ty7uycc2nK2QTq94E65wYrZxOoP4nknBus3E2goeZ+DtQ5l67cTaDeAnXODVLOJ9BOv4rknEtTzibQ/HhIoF3eBHXOpSeHE2hUdW+BOufSlbMJNC+0QNu9BeqcS1POJtD8cBm+s8tboM659ORsAs3zc6DOuUHK2QTacw60w8+BOufSlPMJ1Fugzrl05WwCjceE5OdAnXPpy9kECtGFpA5/FMk5l6acTqB5cdHR6S1Q51x6cjuBxkSnt0Cdc2nK6QRakBejw8+BOufSlNMJNC8W86vwzrm05XYCjcvvA3XOpS2jCVTSAklrJa2XdEMvy3xI0mpJqyT9LKH8GkmvhuGaTMRXmBejrcMTqHMuPRl7K6ekOHAbcCGwFVguaUni64klzQNuBM41s32SJoby8cC/ArWAAc+FdfcNZYylhXk0t3cO5Sadczkkky3QM4H1ZrbBzNqBxcBlSct8AritJzGa2e5QfjHwiJk1hHmPAAuGOsCSgjhN7V1DvVnnXI7IZAKdBmxJmN4ayhIdBxwn6SlJyyQtGMC6SFokqU5SXX19/YADLC3wFqhzLn3ZvoiUB8wDLgCuAr4naVx/VzazO8ys1sxqa2pqBrzzksI8mtu8BeqcS08mE+g2YEbC9PRQlmgrsMTMOsxsI7COKKH2Z91BKy2I0+QtUOdcmjKZQJcD8yTNkVQALASWJC3za6LWJ5KqiQ7pNwAPARdJqpJUBVwUyoZUSYG3QJ1z6cvYVXgz65R0LVHiiwN3mtkqSbcAdWa2hDcS5WqgC/i8me0FkPRFoiQMcIuZNQx1jKWFUQu0u9uIxTTUm3fOjXEZS6AAZrYUWJpUdlPCuAGfC0PyuncCd2YyvpryQroN9jS1MbG8KJO7cs6NQdm+iJRVUyqLAdixvzXLkTjnRqMcT6BRq3PHgZYsR+KcG41yOoFOGxe1QLd5C9Q5l4acTqDjSvIpLYizdV9ztkNxzo1C/Uqgkj7Yn7LRRhLTq0rYus8P4Z1zA9ffFuiN/SwbdaZXFXsCdc6lpc/bmCRdArwXmCbp2wmzKoAx8QjP9Kpint045LeYOudywNHuA90O1AGXAs8llDcCn81UUMNpelUJjW2dHGjuoLIkP9vhOOdGkT4TqJmtAFZI+pmZdQCERytnDHXfnNkyvSq6Er9lXzOVJZVZjsY5N5r09xzoI5IqQkfHzxP1mvTNDMY1bGaMLwHwK/HOuQHrbwKtNLODwAeAH5vZWcC7MxfW8DncAm3wC0nOuYHpbwLNkzQF+BDwQAbjGXaVxflUFOWxucFboM65gelvAr2FqOek18xsuaS5wKuZC2v4SGLWhFI2eQJ1zg1Qv3pjMrOfAz9PmN4AXJGpoIbbzAklrNp2INthOOdGmf4+iTRd0q8k7Q7DLyRNz3Rww2XW+OhppM4uf8Wxc67/+nsI/0Oi3uSnhuE3oWxMmDWhhM5uY7t3KuKcG4D+JtAaM/uhmXWG4S5g4G9xG6Fmji8FYFNDU5Yjcc6NJv1NoHsl/ZWkeBj+CtibycCG06wJ0b2gm/b6hSTnXP/1N4H+DdEtTDuBHcCVwEczFNOwm1xRRFF+jI17vAXqnOu//r4T6Rbgmp7HN8MTSV8jSqyjXiwm5lSXsaH+ULZDcc6NIv1tgZ6S+Ox7eEPm6UdbSdICSWslrZd0Q4r5H5VUL+nFMHw8YV5XQnny65CH3DE1pbxW7y1Q51z/9bcFGpNUldQCPVpXeHHgNuBCYCuwXNISM1udtOi9ZnZtik20mNlp/Yxv0I6dWMaDL+2gtaOLovz4cO3WOTeK9TeBfh14WlLPzfQfBL50lHXOBNaHm+6RtBi4DEhOoCPCMTVlmMHGPU2cMKUi2+E450aBfh3Cm9mPiToS2RWGD5jZT46y2jRgS8L01lCW7ApJKyXdL2lGQnmRpDpJyyRdnmoHkhaFZerq6+v7U5VeHTepHIB1uxoHtR3nXO7o90vlzGy1mX0nDEPVivwNMNvMTgEeAX6UMG+WmdUCVwP/KemYFDHdYWa1ZlZbUzO421Ln1pRSkBdj9faDg9qOcy53ZPKtnNuAxBbl9FB2mJntNbO2MPl94IyEedvC5wbgcfpx0Wow8uMxjp9UzuodnkCdc/2TyQS6HJgnaY6kAmAh0eOgh4Uu8npcCqwJ5VWSCsN4NXAuw3Du9MQpFazefhAzy/SunHNjQMYSqJl1AtcSdYO3BrjPzFZJukXSpWGx6yStkrQCuI43bs4/AagL5Y8Btw7haYNenTClnL1N7exubDv6ws65nNffq/BpMbOlwNKkspsSxm8kxeuRzexPwMmZjC2VE6dG70Ravf0gkyqKhnv3zrlRJpOH8KPO/CnRlXg/D+qc6w9PoAkqivKZOb7Er8Q75/rFE2iSE6dUsGq7907vnDs6T6BJ3jKtgtf3NnOgpSPboTjnRjhPoElOmT4OgJf9HUnOuaPwBJrklOnRlfgVW/dnNxDn3IjnCTTJuJICZk8oYcWW/dkOxTk3wnkCTeGU6eNYudUP4Z1zffMEmsKpM8ax40ArOw/4Wzqdc73zBJrCmbPHA/DMxjHz3jznXAZ4Ak3hxKkVlBfmsWxDQ7ZDcc6NYJ5AU4jHxJlzxvPMBm+BOud65wm0F2fNHc+GPU3sPujnQZ1zqXkC7cXZcycAsGyjH8Y751LzBNqLE6f0nAf1w3jnXGqeQHuRF49RO7vKE6hzrleeQPtw9twJbKhvYnejnwd1zr2ZJ9A+vP2YagCeXLcny5E450YiT6B9OGlqBTXlhTy6dne2Q3HOjUCeQPsQi4l3HT+RJ9bW09HVne1wnHMjTEYTqKQFktZKWi/phhTzPyqpXtKLYfh4wrxrJL0ahmsyGWdf3jl/Io1tndS9vi9bITjnRqiMvZVTUhy4DbgQ2Aosl7QkxeuJ7zWza5PWHQ/8K1ALGPBcWHfYs9g75lVTmBfjoVU7OeeYCcO9e+fcCJbJFuiZwHoz22Bm7cBi4LJ+rnsx8IiZNYSk+QiwIENx9qmsMI93zZ/IAyt30NVt2QjBOTdCZTKBTgO2JExvDWXJrpC0UtL9kmYMZF1JiyTVSaqrr68fqrjf5M9PncqeQ21+T6hz7gjZvoj0G2C2mZ1C1Mr80UBWNrM7zKzWzGpramoyEiDAu+ZPpLQgzq9e2JaxfTjnRp9MJtBtwIyE6emh7DAz22tmbWHy+8AZ/V13OBXlx7ns9GksWbGdvYfajr6Ccy4nZDKBLgfmSZojqQBYCCxJXEDSlITJS4E1Yfwh4CJJVZKqgItCWdZ87O2zae/s5p5nN2czDOfcCJKxBGpmncC1RIlvDXCfma2SdIukS8Ni10laJWkFcB3w0bBuA/BFoiS8HLgllGXNvEnlnH9cDT96ehOtHV3ZDMU5N0LIbGxcWa6trbW6urqM7uPp1/Zy1feW8S/vO4GPnzc3o/tyzo0Mkp4zs9pU87J9EWlUOeeYCZw3r5r/evw1DrV1Zjsc51yWeQIdoH+66Hgamtr5wZMbsx2Kcy7LPIEO0GkzxnHxSZP47hOvsW1/S7bDcc5lkSfQNPzL+06k24x/W7Iq26E457LIE2gaZowv4bp3z+Ph1btYsmJ7tsNxzmWJJ9A0feK8uZw+cxxf+OVLbGloznY4zrks8ASapvx4jG8vPB2A6xa/4PeGOpeDPIEOwozxJXzlylN4YfN+/unnK+j23pqcyymeQAfpkpOncOMl83lw5Q6++OBqxsqDCc65o8tYh8q5ZNH5c9l5sJUfPvU6rR3d/PvlbyEeU7bDcs5lmCfQISCJm95/IiUFcW577DUOtnTwzQ+fRkGeN/CdG8s8gQ4RSXz+4vmMKy7gS0vXcKClg9s/cgZlhf4VOzdWeRNpiH3i/Ll8/YOn8vSGvVx1xzLqG73/UOfGKk+gGXDFGdP5/l/Xsn73Ia68/U9s2tuU7ZCccxngCTRD3jl/Ind/4iwOtHTw4e8u85vtnRuDPIFm0FtnVrF40dm0dHRx9fc9iTo31ngCzbD5kyv48d+cyYHmDj703adZv/tQtkNyzg0RT6DD4NQZ47j3k+fQ0WV86LtP8/K2A9kOyTk3BDyBDpMTplRw/6fOoTg/zsI7lvGrF7b6U0vOjXIZTaCSFkhaK2m9pBv6WO4KSSapNkzPltQi6cUw3J7JOIfL7OpS7v/0OcyfXM5n713BVd9bxoot+7MdlnMuTRm7y1tSHLgNuBDYCiyXtMTMVictVw78A/BM0iZeM7PTMhVftkypLObeT57DT5dt4tt/eJXLbnuKc4+dwDXnzObdJ0zyR0CdG0Uy2QI9E1hvZhvMrB1YDFyWYrkvAl8GWjMYy4gSj4lr3j6bP17/Tq5fcDwb6ptY9JPnOP8rj/GdR19l98Gc+SqcG9UymUCnAVsSpreGssMkvRWYYWYPplh/jqQXJP1R0nkZjDNrygrz+LsLjuXJ69/Jf//lW5k1oYSvPbyOc259lE/+pI4/rqv3LvKcG8Gy9qC2pBjwDeCjKWbvAGaa2V5JZwC/lnSSmR1M2sYiYBHAzJkzMxxx5uTFY1xy8hQuOXkKG/c0sfjZzfz8ua08tGoXc6tL+ft3Hstlp00lL+7X/JwbSZSpK8GSzgFuNrOLw/SNAGb2/8J0JfAa0HNj5GSgAbjUzOqStvU48M/J5Ylqa2utrq7X2aNOW2cXv3t5J7f/cQNrdhxkxvhiPnL2LD54xgyqSguyHZ5zOUPSc2ZWm3JeBhNoHrAOeDewDVgOXG1mKV9lmZgkJdUADWbWJWku8CRwspk19La/sZZAe5gZj6zexff/dyPPbmygIC/G+0+ewlVnzaR2VhWSX3RyLpP6SqAZO4Q3s05J1wIPAXHgTjNbJekWoM7MlvSx+vnALZI6gG7gU30lz7FMEhedNJmLTprM2p2N/HTZJn79wjZ++cI25k0s4+qzZnLlGdMpL8rPdqjO5ZyMtUCH21htgabS3N7JAyt2cPezm1mxZT9lhXlcecZ0rnn7bOZUl2Y7POfGlKwcwg+3XEqgiV7csp8f/el1Hli5nc5u48+Oq+HqM2fyrvkT/aKTc0PAE2gO2N3Yyt3LNrN4+WZ2HWxjckURH37bDK46cyaTK4uyHZ5zo5Yn0BzS2dXNH17Zzd3PbObJV+uJSVx80iT+6uxZnDN3gl90cm6AsnIRyWVHXjzGxSdN5uKTJrNpbxN3P7OZ++q2sPSlnZw3r5p/v/wtzJrg50mdGwreAs0BrR1d3PPsZr7+8Do6urr52Llz+Ph5c6guK8x2aM6NeH4I7wDYdbCV/1i6hiUrtlOYF+MvTp/Gn586lbPmTPBOTJzrhSdQd4TX6g9x++Ov8cDKHbR0dFFTXsh73zKZ950yldNnjiPfr947d5gnUJdSc3snj76ymwdW7OCxtbtp6+ymKD/G6TOqeNvsKmpnj+f0meP8Jn2X0zyBuqM61NbJE+vqWf56A3Wv72PV9gN0G8QU9aZfO6uKU6aP44QpFRw7sYyCPG+lutzgCdQN2KG2Tl7cvD9KqJsaeH7Tflo6ugDIj4tjJ5Zz4pQK5k8uZ96kMo6fXM7kiiK/TcqNOX4bkxuwssI83jGvmnfMqwai+0tf39vEqu0HWbOjkTU7DvLEq/X84vmth9epLM5n/uRyjp9czrxJ5Rw/qZzjJpUxrsR7j3JjkydQ1y958RjHTizn2InlXHbaG+X7mtpZt6uRdbsaWbMzSqy/fH4bh9o6Dy8zsbyQ4yaFluqkKLkeO7GMymI/t+pGN0+gblCqSgs4a+4Ezpo74XCZmbHjQOvhxLpu1yHW7Wpk8bNbDp8GABhXks+sCaXMGl/C7AklzJxQGj5LqCkr9NMBbsTzBOqGnCSmjitm6rhiLjh+4uHy7m5j2/4W1u5sZOOeJl7f28TmhmZe2LKPB1ZuJ/HtJSUFceZUl3LK9HGcMr2S4yaVMae6jKqSfE+sbsTwBOqGTSwmZowvYcb4kjfNa+/sZtv+FjbtbWLT3mY27W3m1d2NPLByO/c8u/nwchVFecyuLmVGVQnTq4qZPj76nFEVJeySAv9Ju+HjvzY3IhTkxZhTXfqm/kx7Wq3rdr3Rat20t5nVOw7yyOpdtHd1H7F8VUk+06qKmRkS9czxJYeT7bSqYgrz4sNZLTfGeQJ1I1pfrdbubqP+UBtbGprZtr+FrfuiYfv+Fl7Z2cjvV+9+U4KtLitg6rhiJlcUMbmyiInlhUyqKGJSmJ5cWUR5YZ6fJnD94gnUjVqxmA4nv1Q36XV3G7saW9m0t5ltIbnuONDCjgOtbNzTxDMbGzjQ0vGm9Yrz40yqKGRieRHV5QXUlBUysaKImvJCqssKmFBayPjSAqrLCiku8BZtLvME6sasWExMqSxmSmVxr8u0dnSx+2AbOw+2RsOBlsPT9Y1trN3ZyP827uFga2fK9UsK4lSVFFBVmh99lhQwvrSAcSXRdEVxHuNCeVVJPuNKCqgo8hbuWOEJ1OW0ovw4M8OtU31pae9iz6E29ja1szd87jnURsOhdhqa29nf3EFDUztbGpppaGrvNeFC9CRXZXEBlcV5VBbnU16UT0VxPhVFeZQVRWVlhXmHh9LCPCqK8iktjFMapkvy48S8B62sy2gClbQA+BbRWzm/b2a39rLcFcD9wNt63v0e3iP/t0AXcJ2ZPZTJWJ3rS3FBvNdzsal0dHVzoKWDAy0d7G/uYH9zO/vC596m9mhecwf7W9rZ39zOpr1NHGjpoKmt603nbXtTWhAl1J7kG33mU1GcFz7zqUwYigvilBdGSbqkII/ywjxPwoOUsQQqKQ7cBlwIbAWWS1piZquTlisH/gF4JqHsRGAhcBIwFfi9pOPMrAvnRoH8eIzqssIBd1ptZrR1dtPY2smhtk6a2qLPxtY3xpsOl3fR1NZJY1sHB1s6aWhq5/U9TRxs7eRgSwed3Ufv56KkIE5ZYR5F+XEK82KUFUWt3uL8KDkXF8TJi4nyojfK8uIxBIwvLaA4P05hfoyi/DglBXFK8qN1ikLZWO8aMZMt0DOB9Wa2AUDSYuAyYHXScl8Evgx8PqHsMmCxmbUBGyWtD9t7OoPxOpd1kijKj1OUH6emPP03BpgZze1dNLZ2sq+5nYMtHTS2dtLc0UVjawfNbV00tnVyqLWT5vZOWju6aG6PhkNtndQ3tnGoLSpv7+zmUFsn/cjHb5IXE+NLC8Kpiuj0w4b6qLU9a0IJx9SUcfVZMzl5WiV5cVEQj42q88OZTKDTgC0J01uBsxIXkPRWYIaZPSjp80nrLktad1ryDiQtAhYBzJw5c4jCdm70k3T4fOlQvJXVzGjv6qYptHpbO7ro7DZaO7po7eimtaOLlo4uWtq7aO7oorU9THd00XCo/XAreceBVrbtbwFg1faDrNp+kCUrtqfc5zE1pVSXFVJelE88BtVlhZQUxCnIi1GYFycmiMdizKkuobK4gIK8GHkxUVwQP9wyLs6PU5gXJz+ujCTmrF1EkhQDvgF8NN1tmNkdwB0QdWc3NJE555JJojAvSkbjS4emd62mtk5e2dnIc5sa6OqG7zz6KidMqaBu0z4AtjS00NltbNrbzP6Wdrq6jY6u9P6bS1CSH6fb4B/fM49P/tkxQ1KHTCbQbcCMhOnpoaxHOfAW4PHwl2EysETSpf1Y1zk3ypUW5nHGrCrOmFUFwKcv6F9S6+jqprmti/pDbbSGzmn2N3ew62Ar+XkxWtu76DKjpb2Lts5u9jW3s21fC5Ul+ew+2Mqso9xxMRCZTKDLgXmS5hAlv4XA1T0zzewAUN0zLelx4J/NrE5SC/AzSd8guog0D3g2g7E650aJ/HiMypIYlSXZ7w4xYwnUzDolXQs8RHQb051mtkrSLUCdmS3pY91Vku4juuDUCfy9X4F3zo00/koP55zrQ1+v9BjbN2k551wGeQJ1zrk0eQJ1zrk0eQJ1zrk0eQJ1zrk0eQJ1zrk0jZnbmCTVA5sGuFo1sCcD4WSD12XkGSv1gNyuyywzq0k1Y8wk0HRIquvt/q7Rxusy8oyVeoDXpTd+CO+cc2nyBOqcc2nK9QR6R7YDGEJel5FnrNQDvC4p5fQ5UOecG4xcb4E651zaPIE651yacjaBSlogaa2k9ZJuyHY8ySTdKWm3pJcTysZLekTSq+GzKpRL0rdDXVaGd031rHNNWP5VSddkqS4zJD0mabWkVZL+YbTWR1KRpGclrQh1+bdQPkfSMyHmeyUVhPLCML0+zJ+dsK0bQ/laSRcPd11CDHFJL0h6YJTX43VJL0l6UVLPq9Ez//sys5wbiDp4fg2YCxQAK4ATsx1XUoznA28FXk4o+wpwQxi/AfhyGH8v8FtAwNnAM6F8PLAhfFaF8aos1GUK8NYwXg6sA04cjfUJMZWF8Xyi13GfDdwHLAzltwOfDuN/B9wexhcC94bxE8PvrhCYE36P8Sz823wO+BnwQJgerfV4HahOKsv472tYKzlSBuAc4KGE6RuBG7MdV4o4Zycl0LXAlDA+BVgbxr8LXJW8HHAV8N2E8iOWy2K9/ge4cLTXBygBnid62+weIC/590X0RoZzwnheWE7Jv7nE5YYx/unAH4B3AQ+EuEZdPcJ+UyXQjP++cvUQPtUrl9/02uQRaJKZ7QjjO4FJYby3+oy4eoZDv9OJWm6jsj7hsPdFYDfwCFGra7+ZdaaI63DMYf4BYAIjoy7/CVwPdIfpCYzOegAY8LCk5xS97hyG4feVtdcau8ExM5M0qu5Bk1QG/AL4RzM7qIT3dI+m+lj0fq7TJI0DfgXMz25EAyfp/cBuM3tO0gVZDmcovMPMtkmaCDwi6ZXEmZn6feVqC3S0vjZ5l6QpAOFzdyjvrT4jpp6S8omS591m9stQPGrrA2Bm+4HHiA51x0nqaZAkxnU45jC/EthL9utyLnCppNeBxUSH8d9i9NUDADPbFj53E/1RO5Nh+H3lagI9/MrlcJVxIdDrW0JHkCVAz5XBa4jOJfaU/3W4ung2cCAcujwEXCSpKlyBvCiUDStFTc0fAGvM7BsJs0ZdfSTVhJYnkoqJzuWuIUqkV4bFkuvSU8crgUctOsG2BFgYrm7PYZhf3W1mN5rZdDObTfT7f9TM/pJRVg8ASaWSynvGiX4XLzMcv6/hPtk7UgaiK3HriM5ffSHb8aSI7x5gB9BBdC7mb4nOOf0BeBX4PTA+LCvgtlCXl4DahO38DbA+DB/LUl3eQXSOaiXwYhjeOxrrA5wCvBDq8jJwUyifS5Q41gM/BwpDeVGYXh/mz03Y1hdCHdcCl2Txt3YBb1yFH3X1CDGvCMOqnv/Pw/H78kc5nXMuTbl6CO+cc4PmCdQ559LkCdQ559LkCdQ559LkCdQ559LkCTTHSfpT+Jwt6eoh3vb/SbWvTJF0uaSbMrTtQxna7gU9PSENYhuvS6ruY/5iSfMGsw+XmifQHGdmbw+js4EBJdCEJ1Z6c0QCTdhXplwP/NdgN9KPemXcEMfw30TfjRtinkBzXELL6lbgvNCf4mdDhxlflbQ89Jn4ybD8BZKelLQEWB3Kfh06cVjV05GDpFuB4rC9uxP3FZ4A+aqklxX14fjhhG0/Lul+Sa9Iujs8xYSkWxX1J7pS0tdS1OM4oM3M9oTpuyTdLqlO0rrw7HdPRyD9qleKfXxJUT+gyyRNStjPlQnLHErYXm91WRDKngc+kLDuzZJ+Iukp4CfhqadfhFiXSzo3LDdB0sPh+/4+0Y3hPU/kPBhifLnnewWeBN4zEv4wjDnZevrBh5ExAIfC5wWEp1HC9CLgX8J4IVBH1N/jBUATMCdh2Z4nPIqJns6ZkLjtFPu6gqgXozhRDzmbiboTu4Col5/pRH/cnyZ6imkC0VMuPQ9+jEtRj48BX0+Yvgv4XdjOPKKnuYoGUq+k7Rvw52H8KwnbuAu4spfvM1Vdioh6/JlHlPju442ngG4GngOKw/TPiDrJAJhJ9CgswLd54wmo94XYqsP3+r2EWCoTxh8Bzsj2722sDd4Cdb25iOh54ReJup6bQPSfHuBZM9uYsOx1klYAy4g6Yzja+bZ3APeYWZeZ7QL+CLwtYdtbzayb6JHP2USJqBX4gaQPAM0ptjkFqE8qu8/Mus3sVaLOcecPsF6J2on6zIQoyc0+Sh17q8t8YKOZvWpRZvtp0jpLzKwljL8H+E6IdQlQoahHq/N71jOzB4F9YfmXgAslfVnSeWZ2IGG7u4Gp/YjZDYA36V1vBHzGzI7oTEFR12dNSdPvIepEt1nS40StrHS1JYx3EXXu2ynpTODdRB1ZXEvUe1CiFqIeghIlP6ds9LNeKXSEhHc4rjDeSTgVJilG9IaDXuvSx/Z7JMYQA842s9akWFOuaGbrFL2e4r3Av0v6g5ndEmYXEX1Hbgh5C9T1aCR63UaPh4BPK+qGDknHKerpJlklsC8kz/lEr0jo0dGzfpIngQ+H85E1RC2qXnvwCa2uSjNbCnwWODXFYmuAY5PKPigpJukYog4n1g6gXv31OnBGGL+U6DUffXkFmB1igqgX9N48DHymZ0LSaWH0CcIFP0mXEL1+AklTgWYz+ynwVaJXwvQ4juj0ihtC3gJ1PVYCXeFQ/C6iviFnA8+Hix/1wOUp1vsd8ClJa4gS1LKEeXcAKyU9b1FXaT1+RdSH5gqiVuH1ZrYzJOBUyoH/kVRE1IL8XIplngC+LkkJLcXNRIm5AviUmbWGiy79qVd/fS/EtoLou+irFUuIYRHwoKRmoj8m5b0sfh1wm6SVRP9XnwA+BfwbcI+kVcCfQj0BTga+KqmbqBevTwOEC14tZrYz/Wq6VLw3JjdmSPoW8Bsz+72ku4guztyf5bCyTtJngYNm9oNsxzLW+CG8G0v+g+hFb+5I+4EfZTuIschboM45lyZvgTrnXJo8gTrnXJo8gTrnXJo8gTrnXJo8gTrnXJr+P1Jj/qD1X5sXAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 360x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0]\n",
      "Your submission was successfully saved!\n"
     ]
    }
   ],
   "source": [
    "inputLayer = train_x.shape[0]\n",
    "evaIter = 100\n",
    "#evaluateHyper(inputLayer, evaIter, train_x_np, train_y_np)\n",
    "\n",
    "dim = [inputLayer, 5, 3, 1]\n",
    "accuracyList = []\n",
    "\n",
    "#Using the best hyperparameters after having visualised the cost functions\n",
    "#Calculating accuracy on the training for many training iterations\n",
    "for i in range(1):\n",
    "    parameters = L_layer_model(train_x_np, train_y_np, dim, learning_rate = 0.1, num_iterations = 5000, print_cost = True, print_plot = True)\n",
    "    accuracy, predictions = predict(train_x_np, train_y_np, parameters)\n",
    "    accuracyList.append(accuracy)   \n",
    "\n",
    "# plotting the variation in accuracy after many iterations\n",
    "plt.plot(np.squeeze(accuracyList))\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Iterations')\n",
    "plt.title(\"Variation in Accuracy\")\n",
    "plt.show()\n",
    "\n",
    "#Calculating predictions on the test set\n",
    "pred_test = predict_for_test(test_x_np, parameters)\n",
    "pred_test_T = pred_test.transpose()\n",
    "pred_test_T = np.squeeze(pred_test_T)\n",
    "pred_test_ints = [int(item) for item in pred_test_T]\n",
    "print(pred_test_ints)\n",
    "\n",
    "output = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': pred_test_ints})\n",
    "output.to_csv('my_submission.csv', index=False)\n",
    "print(\"Your submission was successfully saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "existing-corner",
   "metadata": {
    "papermill": {
     "duration": 0.03868,
     "end_time": "2021-04-18T20:00:51.598240",
     "exception": false,
     "start_time": "2021-04-18T20:00:51.559560",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 13.532101,
   "end_time": "2021-04-18T20:00:52.248040",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-04-18T20:00:38.715939",
   "version": "2.3.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
